{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transferência de aprendizado\n",
        "Desafio: contruir uma arquitetura capaz de classificar imagens entre Muffin ou Chihuahua com base no dataset https://www.kaggle.com/datasets/samuelcortinhas/muffin-vs-chihuahua-image-classification?select=test utilizando a transferência de aprendizado de duas redes já existentes a VGG-16 e a ResNet50. \n",
        "\n",
        "A VGG-16 é uma rede neural de aprendizado profundo criada em 2014 formada de uma pilha de camadas de Convolução, MaxPooling e conectadas por camadas Dense.\n",
        "\n",
        "Já a rede ResNet50 foi criada em 2015 com o objetivo de lidar com o problema de \"degradação de desempenho\" onde a rede profunda começa a perde a eficácia ao adicionar camadas adicionais, para isso foi adotada uma abordagem onde camadas adicionai são inseridas com a sima dos resultados da camada anterior e da camada atual."
      ],
      "metadata": {
        "id": "MGj_nqSUMFKS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Código abaixo refere-se a preparação do ambiente "
      ],
      "metadata": {
        "id": "RnE3NQnG62YG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "5mT34pSG7Crw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16, ResNet50\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Input, Concatenate\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import EarlyStopping "
      ],
      "metadata": {
        "id": "5cUkqLvs7nKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importando as duas redes VGG-16 e ResNet50"
      ],
      "metadata": {
        "id": "qJr3lt9v7vZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model = VGG16(\n",
        "    weights='imagenet', # tipo de treinamento que foi realizado nessa rede\n",
        "    input_shape = (224,224,3) # dimensões da imagem de entrada\n",
        ")\n",
        "resnet50_model = ResNet50(\n",
        "    weights='imagenet', # tipo de treinamento que foi realizado nessa rede\n",
        "    input_shape = (224,224,3) # dimensões da imagem de entrada\n",
        ")"
      ],
      "metadata": {
        "id": "-gUN2-pK71gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como vamos realizar uma transferência de aprendizado é importante “congelar” os pesos das camadas que já foram ajustados. Essa estratégia também previne o overfitting e torna o treinamento mais rápido."
      ],
      "metadata": {
        "id": "-fT_w3XK9s9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Percorre todas as camadas da VGG16 e seta o \"trainable\" como False\n",
        "for l in vgg16_model.layers:\n",
        "    l.trainable = False\n",
        "\n",
        "for l in resnet50_model.layers:\n",
        "    l.trainable = False"
      ],
      "metadata": {
        "id": "bI34I5-G-QUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código a seguir é responsável por concatenar as redes VGG16 e ResNet50. \n",
        "Para isso será criado uma camada de input, concatenado as redes VGG15 e ResNet50 e posteriormente duas camadas densas."
      ],
      "metadata": {
        "id": "Xzwm9doa-zOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# camada de entrada\n",
        "input_tensor = Input(shape=(224,224,3))\n",
        "\n",
        "vgg16_outputs = vgg16_model(input_tensor)\n",
        "\n",
        "resnet50_outputs = resnet50_model(input_tensor)\n",
        "\n",
        "# Concatenando\n",
        "merged_outputs = Concatenate()([vgg16_outputs, resnet50_outputs])\n",
        "\n",
        "# Criando uma camada densa \n",
        "modelo = Dense(128, activation = 'relu')(merged_outputs)\n",
        "               #.        #               # A saída de merge é a entrada dessa camada\n",
        "               #.        # Impedir números negativos \n",
        "               #. quantidade de neurôneos  \n",
        "modelo = Dense(2, activation = 'softmax')(modelo)\n",
        "               #         #                #A saída do modelo é a entrada dessa camada \n",
        "               #         # converter as saídas em probabilidade,\n",
        "               # Quantidade de neurôneos \n",
        "\n",
        "# Cria o modelo final \n",
        "modelo_final = Model(inputs=input_tensor, outputs=modelo)"
      ],
      "metadata": {
        "id": "iwMDna08AU_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizar a arquitetura criada"
      ],
      "metadata": {
        "id": "TYmbnVlbMbfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_final.summary()"
      ],
      "metadata": {
        "id": "70T7ihGpVHw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Modelo está estruturado, porém para dar continuidade é necessário compilar"
      ],
      "metadata": {
        "id": "S8l-_hUzxnwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_final.compile(\n",
        "    optimizer='adam', # Otimizador de pesos \n",
        "    loss='categorical_crossentropy', #Função de perda para avaliação de desempenho \n",
        "    metrics=['accuracy'] # definir a métrica para avaliar o desempenho\n",
        ")"
      ],
      "metadata": {
        "id": "zORSqXX_MeS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As linhas a seguir são responsáveis por acessar os arquivos de estudo do problema"
      ],
      "metadata": {
        "id": "T-ZXftIjcBUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diretorio_treino = \"/content/drive/.../muffin-chihuahua/train\"\n",
        "diretorio_validacao = \"/content/drive/.../muffin-chihuahua/test\"\n",
        "\n",
        "# Analisando as imagens, é notado a necessidade de normalizar \n",
        "# com relação a quantidade de Bits.identifiquei que elas possuem dimensões diferentes\n",
        "# O código abaixo prepara uma variável que receberá as imagens, \n",
        "# ele está pre configurado para torma as imagens no padrão 8 bits\n",
        "dados_treino = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "dados_validacao = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "# Carrega as imagens da pasta e prepara para serem usadas como entrada em uma rede\n",
        "dados_treino = dados_treino.flow_from_directory(\n",
        "    diretorio_treino, # caminho dos arquivos \n",
        "    target_size=(224,224), # redimencionando as imagens para 224X224\n",
        "    class_mode= \"categorical\", # define o tipo de saida categorica\n",
        "    batch_size= 32 # numero de amostras usadas para cada interação de treinamento\n",
        ")\n",
        "\n",
        "dados_validacao = dados_validacao.flow_from_directory(\n",
        "    diretorio_validacao, \n",
        "    target_size=(224,224),\n",
        "    class_mode= \"categorical\", \n",
        "    batch_size= 32 \n",
        ")"
      ],
      "metadata": {
        "id": "K9g0p6xmMldx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chegou o momento de treinar a Rede."
      ],
      "metadata": {
        "id": "30WmerRdambI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_treinado = modelo_final.fit( \n",
        "    dados_treino, \n",
        "    steps_per_epoch = 32,\n",
        "    epochs = 20,\n",
        "    validation_data = dados_validacao,\n",
        "    callbacks=[EarlyStopping(monitor = 'val_accuracy', patience = 2)],\n",
        "    verbose = 1\n",
        ")"
      ],
      "metadata": {
        "id": "-1303mje0lN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui explico a função de cada linha \n",
        "\n",
        "**dados_treino** - corresponde ao nosso diretório com as imagens utilizadas para o treino da rede.\n",
        "\n",
        "**steps_per_epoch** - define o número de passos a serem feitos em cada época\n",
        "\n",
        "**epochs** - número de epocas \n",
        "\n",
        "**validation_data** - dados usados para a validação \n",
        "\n",
        "**callbacks**- o \"EarlyStopping\" monitora a evolução da rede pelo atributo \"val_accuracy\", caso não hava evoluçã em duas épocas a rede encerra o treinamento \n",
        "\n",
        "**verbose** -  define que o processo de treinamento deverá aparece no console "
      ],
      "metadata": {
        "id": "1bakFej11K_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#como estou fazendo vários testes vou salvar em disco o modelo\n",
        "modelo_final.save('/content/drive/..../muffin-chihuahua/modelo_final.h5')\n",
        "# Gerou um arquivo com pouco mais de 600MB \n",
        "\n",
        "# código para carregar um modelo em disco \n",
        "# from keras.models import load_model \n",
        "# modelo_final_carregado = load_model('/content/drive/.../muffin-chihuahua/modelo_final.h5')\n"
      ],
      "metadata": {
        "id": "lgIc9jPgEAwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora chegou a hora dos testes\n",
        "\n",
        "No meu Drive, coloquei algumas fotos de cachorros e bolinhos para testar "
      ],
      "metadata": {
        "id": "FdvIybaZGwbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np \n",
        "\n",
        "# imagem que usarei para teste \n",
        "image_cachorro_teste = \"/content/drive/.../muffin-chihuahua/chihuahua_teste1.jpeg\"\n",
        "\n",
        "# redimensiona a imagem para entrada da rede neural \n",
        "img = image.load_img(image_cachorro_teste, target_size=(224,224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "# solicita para ele predizer a imagem enviada \n",
        "preds = modelo_final.predict(x)"
      ],
      "metadata": {
        "id": "inbeGmkaHFVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Probabilidade \")\n",
        "for classe, indice in dados_validacao.class_indices.items():\n",
        "  print(\"{} : {:.0%}\".format(classe, preds[0][indice]))\n",
        "  "
      ],
      "metadata": {
        "id": "U4aSqhYKStx-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}